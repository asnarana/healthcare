# this migration creates all the database tables we need
# it runs when you do: rails db:migrate
class CreateHealthDataTables < ActiveRecord::Migration[7.1]
  def up
    # this method creates all the tables when migration runs

    # ----------------------------------------------------------------------------
    # table 1: flu data (weekly updates from delphi api)
    # stores weekly flu statistics like how many people have flu-like symptoms
    # ----------------------------------------------------------------------------
    execute <<-SQL
      CREATE TABLE fluview_weekly_rollups (
        id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,  -- auto-incrementing id
        region_code VARCHAR2(20) NOT NULL,  -- 'nat' for national or state code
        epiweek_start DATE NOT NULL,  -- start date of the week
        epiweek_end DATE NOT NULL,  -- end date of the week
        week_number NUMBER NOT NULL,  -- week number in the year (1-52)
        year NUMBER NOT NULL,  -- year (2024, 2025, etc)
        wili NUMBER,  -- weighted influenza-like illness percentage
        ili NUMBER,  -- influenza-like illness percentage
        num_providers NUMBER,  -- how many hospitals/clinics reported
        num_patients NUMBER,  -- total number of patients seen
        num_ili NUMBER,  -- number of patients with flu-like symptoms
        source_name VARCHAR2(50) DEFAULT 'delphi_fluview',  -- where data came from
        last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,  -- when record was last updated
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,  -- when record was created
        CONSTRAINT uk_fluview_region_week UNIQUE (region_code, year, week_number)  -- prevents duplicate data for same region/week
      )
    SQL

    # create index to make queries faster when searching by region and date
    execute "CREATE INDEX idx_fluview_region_period ON fluview_weekly_rollups(region_code, epiweek_start)"

    # ----------------------------------------------------------------------------
    # table 2: hospital capacity data (daily updates from delphi api)
    # stores how many beds are available, occupied, icu beds, covid patients
    # ----------------------------------------------------------------------------
    execute <<-SQL
      CREATE TABLE hospital_capacity_daily_rollups (
        id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,  -- auto-incrementing id
        hospital_pk VARCHAR2(100) NOT NULL,  -- unique hospital identifier
        collection_date DATE NOT NULL,  -- date when data was collected
        state VARCHAR2(2),  -- state code (NY, CA, etc)
        zip_code VARCHAR2(10),  -- zip code of hospital location
        total_beds NUMBER,  -- total number of beds in hospital
        occupied_beds NUMBER,  -- how many beds are currently occupied
        icu_beds NUMBER,  -- total intensive care unit beds
        icu_occupied NUMBER,  -- how many icu beds are occupied
        covid_patients NUMBER,  -- number of covid patients
        source_name VARCHAR2(50) DEFAULT 'delphi_hospital',  -- where data came from
        last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,  -- when record was last updated
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,  -- when record was created
        CONSTRAINT uk_hospital_pk_date UNIQUE (hospital_pk, collection_date)  -- prevents duplicate data for same hospital/date
      )
    SQL

    # create index to make queries faster when searching by zip code and date
    execute "CREATE INDEX idx_hospital_zip_period ON hospital_capacity_daily_rollups(zip_code, collection_date)"

    # ----------------------------------------------------------------------------
    # table 3: fda drug recalls (daily updates from openfda api)
    # stores information about drug recalls and enforcement actions
    # ----------------------------------------------------------------------------
    execute <<-SQL
      CREATE TABLE fda_enforcement_daily_rollups (
        id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,  -- auto-incrementing id
        report_date DATE NOT NULL,  -- date when recall was reported
        recall_number VARCHAR2(50) NOT NULL,  -- unique fda recall number
        product_description VARCHAR2(500),  -- what product was recalled
        reason_for_recall CLOB,  -- why it was recalled (can be long text)
        classification VARCHAR2(20),  -- class I, II, or III (severity)
        status VARCHAR2(50),  -- status of the recall
        state VARCHAR2(2),  -- state where recall happened
        country VARCHAR2(50),  -- country where recall happened
        source_name VARCHAR2(50) DEFAULT 'fda_enforcement',  -- where data came from
        last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,  -- when record was last updated
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,  -- when record was created
        CONSTRAINT uk_fda_recall_number UNIQUE (recall_number)  -- prevents duplicate recalls
      )
    SQL

    # create index to make queries faster when searching by date
    execute "CREATE INDEX idx_fda_enforcement_date ON fda_enforcement_daily_rollups(report_date)"

    # ----------------------------------------------------------------------------
    # table 4: air quality data (hourly updates from openaq api)
    # stores pm2.5 and ozone (o3) measurements for air quality monitoring
    # ----------------------------------------------------------------------------
    execute <<-SQL
      CREATE TABLE openaq_hourly_rollups (
        id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,  -- auto-incrementing id
        location_id VARCHAR2(100) NOT NULL,  -- unique identifier for the monitoring station
        measurement_date DATE NOT NULL,  -- date of the measurement
        measurement_hour NUMBER NOT NULL,  -- hour of day (0-23)
        latitude NUMBER(10, 7),  -- latitude coordinate of monitoring station
        longitude NUMBER(10, 7),  -- longitude coordinate of monitoring station
        zip_code VARCHAR2(10),  -- zip code where station is located
        pm25_value NUMBER,  -- pm2.5 air pollution measurement value
        pm25_unit VARCHAR2(10),  -- unit for pm2.5 (usually µg/m³)
        o3_value NUMBER,  -- ozone (o3) air pollution measurement value
        o3_unit VARCHAR2(10),  -- unit for o3 (usually ppm or µg/m³)
        source_name VARCHAR2(50) DEFAULT 'openaq',  -- where data came from
        last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,  -- when record was last updated
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,  -- when record was created
        CONSTRAINT uk_openaq_location_datetime UNIQUE (location_id, measurement_date, measurement_hour)  -- prevents duplicate data for same location/time
      )
    SQL

    # create index to make queries faster when searching by zip code and date
    execute "CREATE INDEX idx_openaq_zip_period ON openaq_hourly_rollups(zip_code, measurement_date)"

    # ----------------------------------------------------------------------------
    # table 5: ingestion metrics (tracks how well our data collection jobs are running)
    # stores information about each time we fetch data from apis (success/failure, how long it took, etc)
    # ----------------------------------------------------------------------------
    execute <<-SQL
      CREATE TABLE ingestion_metrics (
        id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,  -- auto-incrementing id
        source_name VARCHAR2(50) NOT NULL,  -- which api we fetched from (delphi_fluview, openaq, etc)
        job_run_at TIMESTAMP NOT NULL,  -- when the job ran
        status VARCHAR2(20) NOT NULL,  -- 'success', 'failed', or 'partial'
        records_processed NUMBER DEFAULT 0,  -- how many records we processed
        records_inserted NUMBER DEFAULT 0,  -- how many new records we inserted
        records_updated NUMBER DEFAULT 0,  -- how many existing records we updated
        duration_ms NUMBER,  -- how long the job took in milliseconds
        error_message VARCHAR2(4000),  -- error message if job failed
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL  -- when this metric record was created
      )
    SQL

    # create index to make queries faster when searching by source and time
    execute "CREATE INDEX idx_ingestion_metrics_source_time ON ingestion_metrics(source_name, job_run_at)"
  end

  def down
    # this method runs if you rollback the migration (rails db:rollback)
    # it deletes all the tables we created
    execute "DROP TABLE ingestion_metrics"
    execute "DROP TABLE openaq_hourly_rollups"
    execute "DROP TABLE fda_enforcement_daily_rollups"
    execute "DROP TABLE hospital_capacity_daily_rollups"
    execute "DROP TABLE fluview_weekly_rollups"
  end
end
